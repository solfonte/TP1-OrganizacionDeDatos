{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa841f45",
   "metadata": {},
   "source": [
    "# Ensamble: Boosting\n",
    "\n",
    "Podemos encontrar la documentacion en:  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77eee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, ensemble\n",
    "\n",
    "from preprocessing import cargarDatasets\n",
    "from preprocessing import prepararSetDeEntrenamiento\n",
    "from preprocessing import prepararSetDeValidacion\n",
    "from preprocessing import ingenieriaDeFeauturesArboles1\n",
    "from preprocessing import ingenieriaDeFeauturesArboles2\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b18a6",
   "metadata": {},
   "source": [
    "## Carga y preprocesamiento de datos\n",
    "Cargamos los datasets y los preparamos para entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded3f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,final_df = cargarDatasets()\n",
    "train_df = prepararSetDeEntrenamiento(train_df)\n",
    "final_df = prepararSetDeValidacion(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7268d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAMBIAR PREPROCESAMIENTO PARA XGBOOST\n",
    "X,y,df,y_encoder = ingenieriaDeFeauturesArboles1(train_df)\n",
    "X_reducido,y_reducido,df_reducido,y_encoder_reducido = ingenieriaDeFeauturesArboles2(train_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=117, test_size=0.1, stratify=y)\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reducido, y_reducido, random_state=117, test_size=0.1, stratify=y_reducido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b9d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/prashant111/a-guide-on-xgboost-hyperparameters-tuning\n",
    "#https://www.quora.com/In-what-situations-do-neural-networks-outperform-gradient-boosting-and-random-forest-models-on-regular-numeric-and-categorical-data-non-image-or-text-data-if-any\n",
    "\n",
    "#Como trabaja con arboles, los hiperparametros van a ser similares a los del arbol (tal vez podemos \n",
    "#justificar q por eso usamos los mismos preprocesamientos).\n",
    "#params = {'max_depth': np.arange(1, 10),'min_samples_leaf': np.arange(10,30),\"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b91428",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGboost = ensemble.GradientBoostingClassifier(random_state = 0)\n",
    "#entrenamos con los parametros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
